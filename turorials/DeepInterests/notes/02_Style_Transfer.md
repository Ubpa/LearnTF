# 02. 风格迁移

## 1. 原理

### 1.1 简介

图像风格迁移是指，将一副**内容图**的内容，和一副或多副**风格图**的风格融合在一起，从而生成一些有意思的图片。

以下是将一些艺术作品的风格，迁移到一张内容图之后的效果

![1547795564271](assets/1547795564271.png)

### 1.2 准备

```bash
pip install scipy numpy tensorflow
```

在准备一些风格图片和一张内容图片

### 1.3 原理

为了将风格图的风格和内容图的内容进行融合，所生成的图片，在内容上应尽可能接近内容图，在风格上应当尽可能接近风格图。

因此需要定义**内容损失函数**和**风格损失函数**，经过加权后作为总体损失函数。

实现步骤如下：

- 随机产生一张图片
- 在每轮迭代中，根据总体损失函数，调整图片的像素值
- 经过多轮迭代，得到优化的图片

### 1.4 内容损失函数

两张图片在内容上相似，不能仅仅靠简单的纯像素比较。

`CNN` 具有抽象和理解图像的能力，因此可以考虑将各个卷积层的输出作为图像的内容。

这里使用的 `CNN` 是**预训练**的，在风格迁移的过程中并**不需要训练**这个模型，只是用它的中间输出来表达**内容**和**风格**。

以 `VGG19` 为例，其中包括了多个卷积层、池化层，以及最后的全连接层。

![1547796016954](assets/1547796016954.png)

可以参考 [一文读懂VGG网络](https://zhuanlan.zhihu.com/p/41423739)，重点是**3x3卷积核代替大卷积核**。

> 结构为
>
> ```
> img
> -> 2 x conv3-64 -> pool2
> -> 2 x conv3-128 -> pool2
> -> 4 x conv3-256 -> pool2
> -> 4 x conv3-512 -> pool2
> -> 4 x conv3-512 -> pool2
> -> 2 x FC4096 -> FC1000
> ```

在论文中，作者提到了`average-pooling`比`max-pooling`效果更好，因此，我们重新定义了一个`average-pooling`层。

这里我们使用 `conv4_2` 的输出作为图像的内容表示，定义内容损失函数如下
$$
L _ { \text {content} } ( \vec { p } , \vec { x } , l ) = \frac { 1 } { 2 } \sum _ { i , j } \left( F _ { i j } ^ { l } - P _ { i j } ^ { l } \right) ^ { 2 }
$$

> $\vec p​$ 是内容图片，$\vec x​$ 是生成的图片
>
> $F^l \in \mathcal{R}^{N_l \times M_l}$，$F^l$ 是生成的图片第 `l` 层的特征表示， $F_{i,j}^l​$ 是第 `l` 层，第 `i` 个 `filter` 的特征图的第 `j` 个元素
>
> $P^l$ 是内容图片第 `l` 层的特征表示

### 1.5 风格损失函数

风格是一个很难说清楚的概念，可能是笔触、纹理、结构、布局、用色等等

这里我们使用卷积层各个特征图之间的互相关作为图像的风格，以`conv1_1`为例

- 共包含64个特征图即feature map，或者说图像的深度、通道的个数
- 每个特征图都是对上一层输出的一种理解，可以类比成64个人对同一幅画的不同理解
- 这些人可能分别偏好印象派、现代主义、超现实主义、表现主义等不同风格
- 当图像是某一种风格时，可能这一部分人很欣赏，但那一部分人不喜欢
- 当图像是另一种风格时，可能这一部分人不喜欢，但那一部分人很欣赏
- 64个人之间理解的差异，可以用特征图的互相关表示，这里使用`Gram`矩阵计算互相关
- 不同的风格会导致差异化的互相关结果

`Gram`矩阵的计算如下，如果有64个特征图，那么`Gram`矩阵的大小便是 `64 x 64`，第 `i` 行第 `j` 列的值表示第 `i` 个特征图和第 `j` 个特征图之间的互相关，用内积计算
$$
G _ { i j } ^ { l } = \sum _ { k } F _ { i k } ^ { l } F _ { j k } ^ { l }
$$

> $F_{ik}^l​$ 是 `l` 层第 `i` 个特征图的第 `k` 个元素
>
> G 是一个张量

风格损失函数定义如下，对多个卷积层的风格表示差异进行加权
$$
\begin{array} { l } { E _ { l } = \frac { 1 } { 4 N _ { l } ^ { 2 } M _ { l } ^ { 2 } } \sum _ { i , j } \left( G _ { i j } ^ { l } - A _ { i j } ^ { l } \right) ^ { 2 } } \\ { L _ { s t y l e } ( \vec { a } , \vec { x } ) = \sum _ { l = 0 } ^ { L } \omega _ { l } E _ { l } } \end{array}
$$

> $A^l$ 是风格图的 `Gram` 矩阵，$G^l​$ 是生成的图片的 `Gram` 矩阵
>
> $N_l$ 是第 `l` 层的 `filter` 数，$M_l$ 是 `l` 层特征图的大小 `(width * height)` 
>
> $\vec a​$ 是风格图片，$\vec x​$ 是生成的图片

这里我们使用`conv1_1`、`conv2_1`、`conv3_1`、`conv4_1`、`conv5_1`五个卷积层，进行风格损失函数的计算，不同的权重会导致不同的迁移效果

### 1.6 总的损失函数

总的损失函数即内容损失函数和风格损失函数的加权，不同的权重会导致不同的迁移效果
$$
L _ { t o t a l } ( \vec { p } , \vec { a } , \vec { x } ) = \alpha L _ { c o n t e n t } ( \vec { p } , \vec { x } ) + \beta L _ { s t y l e } ( \vec { a } , \vec { x } )
$$

### 1.7 总结

整个style transfer算法的核心在于content和style信息的捕捉与loss function的设计，通过卷积得到的feature map去捕捉图像的content和style，进而最小化合成图像与原始图像content和style的加权损失，最终学习得到具有style image风格的合成图像。

## 2. 实现

参考 https://zhuanlan.zhihu.com/p/38315161

**内容** 

![resized_sky](assets/resized_sky.jpg)

**风格** 

![resized_style5](assets/resized_style5.jpg)

结果如下

![epoch_299](assets/epoch_299.png)

